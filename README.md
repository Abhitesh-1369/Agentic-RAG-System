# Agentic-RAG-System

This project is a Question-Answering (Q&A) system that leverages a multi-agent Retrieval-Augmented Generation (RAG) architecture. Users can upload documents in various formats and ask questions, receiving intelligent, context-aware answers generated by a large language model.

The application is built with a focus on modularity and clear communication between components, using a Model Context Protocol (MCP) for agent interaction.

---

## Architecture

The system is built on a multi-agent architecture, where each agent has a specialized role. Communication and workflow between these agents are managed by a central `Dispatcher`.

* **Ingestion Agent**: Responsible for parsing uploaded documents, breaking them into manageable text chunks, and converting them into numerical embeddings for storage.
* **Retrieval Agent**: Manages the vector store. When a user asks a question, this agent converts the query into an embedding and retrieves the most relevant document chunks from the vector store.
* **LLM Response Agent**: Receives the user's query and the retrieved context from the Retrieval Agent. It then constructs a precise prompt to send to the Cohere language model to generate a final, human-readable answer.

<img width="400" height="400" alt="image" src="https://github.com/user-attachments/assets/06f72f1d-bae8-45ce-8d84-12cafb0a3831" />


---

## Key Features

* **Multi-Format Document Support**: Ingests and analyzes various document types, including **PDF, DOCX, PPTX, CSV, and TXT**.
* **Agent-Based Workflow**: Utilizes distinct agents for ingestion, retrieval, and response generation, ensuring a modular and scalable design[cite: 18].
* **Advanced LLM Integration**: Leverages the powerful **Cohere Command R+** model for accurate and context-aware answer generation.
* **Efficient Vector Search**: Employs **TF-IDF** for embeddings and **FAISS** for fast, in-memory similarity searches[cite: 37, 40].
* **Interactive Chat Interface**: A clean and modern UI built with **Streamlit** that supports file uploads and displays conversations in a chat-like format.

---

##  Tech Stack

* **Backend**: Python
* **UI Framework**: ipywidgets
* **LLM**: gemini-2.5-flash-lite
* **Vector Embeddings**: all-MiniLM-L6-v2
* **Vector Store**: Facebook AI Similarity Search (FAISS)
* **Document Parsers**: PyMuPDF (for PDF), python-docx, python-pptx, Pandas

---

## Setup and Installation

Follow these steps to set up and run the project.

### 1. Prerequisites

* Python 3.8+
* Huggingface API Key
* Google AI Studio API Key 

### 2. Google Colab Notebook

* Download and Open the notebook.
* Run all the cells with your API Keys

# How to Use
* Run the Notebook.
* Upload a document using the file uploader. Wait for the success message.
* Ask a question about the content of your document in the chat input box at the bottom of the screen.
* View the response generated by the agentic system. You can continue asking follow-up questions about the same document.
